{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DONE FINE Bert implementation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MooNight009/ColabProjects/blob/master/DONE_FINE_Bert_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hjAkbx8SDgv",
        "colab_type": "code",
        "outputId": "d8545dc3-5c48-4717-80f5-9293c43a4725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install bert\n",
        "!pip install nltk\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: erlastic in /usr/local/lib/python3.6/dist-packages (from bert) (2.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.13.0)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.13.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdKRoN3GimwP",
        "colab_type": "code",
        "outputId": "1a115e57-4ece-4708-d042-814abcc1ba30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import bert\n",
        "from bert.tokenization import FullTokenizer\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Eager:\", \"True\" if tf.executing_eagerly else \"False\")\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "TF version: 2.0.0\n",
            "Eager: True\n",
            "GPU is not available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRTamwOfSRhC",
        "colab_type": "code",
        "outputId": "0e1c17af-da1a-4b26-a227-11e3259a40bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "max_seq_len= 15\n",
        "\n",
        "input_word_ids= tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "input_mask= tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "segment_ids= tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "bert_layer= hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable= True)\n",
        "\n",
        "pooled_output, sequence_output= bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "model= tf.keras.Model(inputs= [input_word_ids, input_mask, segment_ids], outputs= [pooled_output, sequence_output])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 109,482,240\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsr-0P6oVro5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_masks(tokens, max_seq_len):\n",
        "  if len(tokens)> max_seq_len:\n",
        "  \n",
        "    raise IndexError(\"Token length is more than max\")\n",
        "  return [1]* len(tokens)+ [0]* (max_seq_len- len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_len):\n",
        "  if len(tokens)> max_seq_len:\n",
        "    raise IndexError(\"Token length is more than max\")\n",
        "  \n",
        "  segments= []\n",
        "  current_segment_id= 0\n",
        "\n",
        "  for token in tokens:\n",
        "    segments.append(current_segment_id)\n",
        "\n",
        "    if token== \"[SEP]\":\n",
        "      current_segment_id+= 1\n",
        "  \n",
        "  return segments+ [0]* (max_seq_len- len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_len):\n",
        "  token_ids= tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "  return token_ids+ [0]* (max_seq_len- len(tokens))\n",
        "\n",
        "\n",
        "# nltk tokenizer has been used to allow for multiple sentences\n",
        "def tokenize(text):\n",
        "  text= text.lower()\n",
        "  sTokens= nltk.sent_tokenize(text)\n",
        "  wTokens= [nltk.word_tokenize(sen) for sen in sTokens]\n",
        "  tokens= []\n",
        "  tokens.append(\"[CLS]\")\n",
        "  for sen in wTokens:\n",
        "    for word in sen:\n",
        "      tokens.append(word)\n",
        "    tokens.append(\"[SEP]\")\n",
        "\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrDI1tq9tzh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(model, tokens, max_seq_length= 128):\n",
        "  vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "  do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "  tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "\n",
        "  input_ids = get_ids(tokens, tokenizer, max_seq_length)\n",
        "  input_masks = get_masks(tokens, max_seq_length)\n",
        "  input_segments = get_segments(tokens, max_seq_length)\n",
        "\n",
        "  # The following was used to bypass shape and len errors\n",
        "  input_ids= np.array(input_ids)\n",
        "  input_masks= np.array(input_masks)\n",
        "  input_segments= np.array(input_segments)\n",
        "\n",
        "  input_ids= input_ids.reshape(-1, 1)\n",
        "  input_masks= input_masks.reshape(-1, 1)\n",
        "  input_segments= input_segments.reshape(-1, 1)\n",
        "\n",
        "  input_ids= np.transpose(input_ids)\n",
        "  input_masks= np.transpose(input_masks)\n",
        "  input_segments= np.transpose(input_segments)\n",
        "\n",
        "\n",
        "  inp= input_ids, input_masks, input_segments\n",
        " \n",
        "\n",
        "  \n",
        "  \n",
        "  pool_embs, all_embs = model.predict(inp)\n",
        "\n",
        "  return pool_embs, all_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2r_MC96WydN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text= \"This is a nice sentence! which follows this\"\n",
        "# getPrediction(model, tokenize(text), max_seq_length= max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}