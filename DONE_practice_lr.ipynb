{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DONE practice lr",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MooNight009/ColabProjects/blob/master/DONE_practice_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5c4738ad-d251-4dae-950d-74aa40de1191",
        "id": "lAzFK33h0Gp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"Eager:\", \"true\" if tf.executing_eagerly else \"false\")\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0-rc1\n",
            "Eager: true\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLiMTECJWOPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read the data\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmNYWJ6hXzz2",
        "colab_type": "code",
        "outputId": "3f7e0ecd-b73b-43a4-b4a4-8d7c914e7d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Shuffle the data\n",
        "california_housing_dataframe= california_housing_dataframe.reindex(np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.562108</td>\n",
              "      <td>35.625225</td>\n",
              "      <td>28.589353</td>\n",
              "      <td>2643.664412</td>\n",
              "      <td>539.410824</td>\n",
              "      <td>1429.573941</td>\n",
              "      <td>501.221941</td>\n",
              "      <td>3.883578</td>\n",
              "      <td>207300.912353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.005166</td>\n",
              "      <td>2.137340</td>\n",
              "      <td>12.586937</td>\n",
              "      <td>2179.947071</td>\n",
              "      <td>421.499452</td>\n",
              "      <td>1147.852959</td>\n",
              "      <td>384.520841</td>\n",
              "      <td>1.908157</td>\n",
              "      <td>115983.764387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.790000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1462.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>790.000000</td>\n",
              "      <td>282.000000</td>\n",
              "      <td>2.566375</td>\n",
              "      <td>119400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.250000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2127.000000</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.544600</td>\n",
              "      <td>180400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.000000</td>\n",
              "      <td>37.720000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3151.250000</td>\n",
              "      <td>648.250000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>605.250000</td>\n",
              "      <td>4.767000</td>\n",
              "      <td>265000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>37937.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  17000.000000  17000.000000  ...   17000.000000        17000.000000\n",
              "mean    -119.562108     35.625225  ...       3.883578       207300.912353\n",
              "std        2.005166      2.137340  ...       1.908157       115983.764387\n",
              "min     -124.350000     32.540000  ...       0.499900        14999.000000\n",
              "25%     -121.790000     33.930000  ...       2.566375       119400.000000\n",
              "50%     -118.490000     34.250000  ...       3.544600       180400.000000\n",
              "75%     -118.000000     37.720000  ...       4.767000       265000.000000\n",
              "max     -114.310000     41.950000  ...      15.000100       500001.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRwBwkpXahY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X= california_housing_dataframe[\"total_rooms\", \"population\", \"total_bedrooms\", \"median_income\"].values\n",
        "X= california_housing_dataframe[['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']].values\n",
        "Y= california_housing_dataframe[\"median_house_value\"].values/ 10000.0\n",
        "\n",
        "# X= np.reshape(X, (-1, 1))\n",
        "Y= np.reshape(Y, (-1, 1))\n",
        "\n",
        "train_features , test_features ,train_labels, test_labels = train_test_split( X , Y , test_size=0.2)\n",
        "\n",
        "X= tf.constant(train_features, dtype=X.dtype)\n",
        "# X= normalize(X)\n",
        "Y= tf.constant(train_labels, dtype=Y.dtype)\n",
        "# Y= normalize(Y)\n",
        "\n",
        "test_X= tf.constant(test_features, dtype=X.dtype)\n",
        "# test_X= normalize(test_X)\n",
        "test_Y= tf.constant(test_labels, dtype=Y.dtype)\n",
        "# test_Y= normalize(test_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8cRoTk0E1sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize the data\n",
        "def normalize(data):\n",
        "  mean, var = tf.nn.moments(data, [0], keepdims= True)\n",
        "  new_tensor = tf.divide(tf.subtract(data, mean), tf.sqrt(var))\n",
        "  return new_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THlWrcvwe6Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_squared_error( Y , y_pred ):\n",
        "    return tf.reduce_mean( tf.square( y_pred - Y ) )\n",
        "\n",
        "def mean_squared_error_deriv( Y , y_pred ):\n",
        "    return tf.reshape( tf.reduce_mean( 2 * ( y_pred - Y ) ) , [ 1 , 1 ] )\n",
        "    \n",
        "def h ( X , weights , bias ):\n",
        "    return tf.tensordot( X , weights , axes=1 ) + bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoltzQezfdoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs= 20\n",
        "num_samples= X.shape[0]\n",
        "batch_size= 10\n",
        "learning_rate= 0.001\n",
        "\n",
        "dataset= tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "dataset= dataset.shuffle(500).repeat(num_epochs).batch(batch_size)\n",
        "iterator= dataset.__iter__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSfXVv_XhM0V",
        "colab_type": "code",
        "outputId": "0b123a58-8337-465e-991f-212331a89cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "num_features = X.shape[1] if len(X.shape)> 1 else 1\n",
        "weights = tf.random.normal( ( num_features , 1), dtype=X.dtype)\n",
        "\n",
        "bias= 0\n",
        "\n",
        "epochs_plot= list()\n",
        "loss_plot= list()\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  epoch_loss= list()\n",
        "  \n",
        "  for b in range(int(num_samples/ batch_size)):\n",
        "    x_batch, y_batch= iterator.get_next()\n",
        "\n",
        "    output = h( x_batch , weights , bias ) \n",
        "    loss = epoch_loss.append( mean_squared_error( y_batch , output ).numpy() )\n",
        "\n",
        "    dJ_dH = mean_squared_error_deriv( y_batch , output)\n",
        "    dH_dW = x_batch\n",
        "    dJ_dW = tf.reduce_mean( dJ_dH * dH_dW )\n",
        "    dJ_dB = tf.reduce_mean( dJ_dH )\n",
        "\n",
        "    \n",
        "\n",
        "    weights -= ( learning_rate * dJ_dW )\n",
        "    bias -= ( learning_rate * dJ_dB ) \n",
        "\n",
        "    \n",
        "    # if b< 2:\n",
        "    #   print(\"Loss\", mean_squared_error( y_batch , output ).numpy())\n",
        "    #   print(\"dJ_dH\", dJ_dH)\n",
        "    #   print(\"Weight\", weights)\n",
        "    #   print(\"Bias\", bias)\n",
        "    #   print(\"Input\", x_batch[:2])\n",
        "    #   print(\"Output\", output[:2])\n",
        "    #   print(\"Expected\", y_batch[:2])\n",
        "\n",
        "\n",
        "    #   print(\"----------------\")\n",
        "  # print(epoch_loss)\n",
        "  loss= np.array(epoch_loss).mean()\n",
        "  epochs_plot.append(i+ 1)\n",
        "  loss_plot.append(loss)\n",
        "\n",
        "  print(\"Loss is {}\".format(loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss is nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-b30d21dbe0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_batch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdJ_dH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error_deriv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-161-13c66f2c521d>\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(Y, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_squared_error_deriv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  10090\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m  10091\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10092\u001b[0;31m         x, y)\n\u001b[0m\u001b[1;32m  10093\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10094\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WexkpSNjyx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs_plot, loss_plot)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WasuKBLy-GjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = h( test_X , weights , bias ) \n",
        "labels = test_Y\n",
        "\n",
        "accuracy_op = tf.metrics.MeanAbsoluteError() \n",
        "accuracy_op.update_state( labels , output )\n",
        "print( 'Mean Absolute Error = {}'.format( accuracy_op.result().numpy() ) )\n",
        "\n",
        "accuracy_op = tf.metrics.RootMeanSquaredError() \n",
        "accuracy_op.update_state( labels , output )\n",
        "print( 'Root Mean Square Error = {}'.format( accuracy_op.result().numpy() ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WojcrNuzmjnC",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "This uses estimator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37256661-e1ba-4e81-89b8-7aeda428ee57",
        "id": "KhvM8eUQ0LwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1.data as tfv1\n",
        "from sklearn import metrics\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"Eager:\", \"true\" if tf.executing_eagerly else \"false\")\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0-rc1\n",
            "Eager: true\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BsXgd6rU0LwT",
        "colab": {}
      },
      "source": [
        "#Read the data\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "96a88134-74d1-4b97-bcff-ffc1387c5d0b",
        "id": "gdzJ_Frg0LwZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Shuffle the data\n",
        "california_housing_dataframe= california_housing_dataframe.reindex(np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
        "california_housing_dataframe.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.562108</td>\n",
              "      <td>35.625225</td>\n",
              "      <td>28.589353</td>\n",
              "      <td>2643.664412</td>\n",
              "      <td>539.410824</td>\n",
              "      <td>1429.573941</td>\n",
              "      <td>501.221941</td>\n",
              "      <td>3.883578</td>\n",
              "      <td>207.300912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.005166</td>\n",
              "      <td>2.137340</td>\n",
              "      <td>12.586937</td>\n",
              "      <td>2179.947071</td>\n",
              "      <td>421.499452</td>\n",
              "      <td>1147.852959</td>\n",
              "      <td>384.520841</td>\n",
              "      <td>1.908157</td>\n",
              "      <td>115.983764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14.999000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.790000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1462.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>790.000000</td>\n",
              "      <td>282.000000</td>\n",
              "      <td>2.566375</td>\n",
              "      <td>119.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.250000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2127.000000</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.544600</td>\n",
              "      <td>180.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.000000</td>\n",
              "      <td>37.720000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3151.250000</td>\n",
              "      <td>648.250000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>605.250000</td>\n",
              "      <td>4.767000</td>\n",
              "      <td>265.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>37937.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500.001000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  17000.000000  17000.000000  ...   17000.000000        17000.000000\n",
              "mean    -119.562108     35.625225  ...       3.883578          207.300912\n",
              "std        2.005166      2.137340  ...       1.908157          115.983764\n",
              "min     -124.350000     32.540000  ...       0.499900           14.999000\n",
              "25%     -121.790000     33.930000  ...       2.566375          119.400000\n",
              "50%     -118.490000     34.250000  ...       3.544600          180.400000\n",
              "75%     -118.000000     37.720000  ...       4.767000          265.000000\n",
              "max     -114.310000     41.950000  ...      15.000100          500.001000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLjfkJIR0Lwe",
        "colab": {}
      },
      "source": [
        "# features= california_housing_dataframe[['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']]\n",
        "input= ['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
        "my_features= california_housing_dataframe[input]\n",
        "# feature_columns = [tf.feature_column.numeric_column('housing_median_age'), tf.feature_column.numeric_column('total_rooms')]\n",
        "feature_columns = [tf.feature_column.numeric_column(x) for x in input]\n",
        "\n",
        "targets= california_housing_dataframe[\"median_house_value\"]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoRIdnfG2yW0",
        "colab_type": "code",
        "outputId": "1a7c03cb-6f32-46bd-d3ea-01f9289d1ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Optimizer\n",
        "my_optimizer= tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# linear_regressor= tf.estimator.LinearRegressor(\n",
        "linear_regressor= tf.estimator.DNNLinearCombinedRegressor(\n",
        "    # feature_columns= feature_columns,\n",
        "    linear_feature_columns= feature_columns,\n",
        "    dnn_optimizer= my_optimizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpomz_5dbn\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpomz_5dbn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II5gknj63cdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_input_fn(features, targets, batch_size= 1, shuffle= True, num_epochs= None):\n",
        "  features= {key:np.array(value) for key, value in dict(features).items()}\n",
        "\n",
        "  dataset= tfv1.Dataset.from_tensor_slices((features, targets))\n",
        "  dataset= dataset.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "  if shuffle:\n",
        "    dataset= dataset.shuffle(buffer_size= 10000)\n",
        "\n",
        "  # iter= eval_input_fn()\n",
        "  # return next(iter)\n",
        "  # return next(dataset.__iter__())\n",
        "  # iterator= dataset.__iter__()\n",
        "  \n",
        "  features, labels = dataset.make_one_shot_iterator().get_next()\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-SGQhY140pE",
        "colab_type": "code",
        "outputId": "ce33386a-3868-46b5-fb80-0ec52da3a819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "linear_regressor.train(\n",
        "    input_fn = lambda:my_input_fn(my_features, targets, num_epochs= 10),\n",
        "    steps= 500\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpomz_5dbn/model.ckpt.\n",
            "INFO:tensorflow:loss = 13665.61, step = 0\n",
            "INFO:tensorflow:global_step/sec: 304.535\n",
            "INFO:tensorflow:loss = 46505.79, step = 100 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.735\n",
            "INFO:tensorflow:loss = 750.6556, step = 200 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 401.647\n",
            "INFO:tensorflow:loss = 13510.231, step = 300 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 387.68\n",
            "INFO:tensorflow:loss = 290.1243, step = 400 (0.258 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 401 vs previous value: 401. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmpomz_5dbn/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 8225.852.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedRegressorV2 at 0x7fb021a24320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeLF-Su_7b5b",
        "colab_type": "code",
        "outputId": "b20ceb24-6c45-4ea3-fa50-fda41468f40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "predictions = linear_regressor.predict(input_fn=lambda: my_input_fn(my_features, targets, batch_size= 1, num_epochs=1, shuffle=False))\n",
        "\n",
        "predictions = np.array([item['predictions'][0] for item in predictions])\n",
        "\n",
        "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
        "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
        "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpomz_5dbn/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Mean Squared Error (on training data): 27278.923\n",
            "Root Mean Squared Error (on training data): 165.163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FCNl7Ka4NMwC"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "This uses simple neural net\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20e07bd8-f17f-4dae-901e-b0ea60bbf491",
        "id": "wAbWeT3wNJ-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"Eager:\", \"true\" if tf.executing_eagerly else \"false\")\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0-rc1\n",
            "Eager: true\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GjE5Pvq3NJ_Q",
        "colab": {}
      },
      "source": [
        "#Read the data\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f9391be-8cbf-4677-e154-ed1cbe182678",
        "id": "-dH7F7WyNJ_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Shuffle the data\n",
        "california_housing_dataframe= california_housing_dataframe.reindex(np.random.permutation(california_housing_dataframe.index))\n",
        "california_housing_dataframe.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "      <td>17000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.562108</td>\n",
              "      <td>35.625225</td>\n",
              "      <td>28.589353</td>\n",
              "      <td>2643.664412</td>\n",
              "      <td>539.410824</td>\n",
              "      <td>1429.573941</td>\n",
              "      <td>501.221941</td>\n",
              "      <td>3.883578</td>\n",
              "      <td>207300.912353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.005166</td>\n",
              "      <td>2.137340</td>\n",
              "      <td>12.586937</td>\n",
              "      <td>2179.947071</td>\n",
              "      <td>421.499452</td>\n",
              "      <td>1147.852959</td>\n",
              "      <td>384.520841</td>\n",
              "      <td>1.908157</td>\n",
              "      <td>115983.764387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>14999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.790000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1462.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>790.000000</td>\n",
              "      <td>282.000000</td>\n",
              "      <td>2.566375</td>\n",
              "      <td>119400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.250000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2127.000000</td>\n",
              "      <td>434.000000</td>\n",
              "      <td>1167.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.544600</td>\n",
              "      <td>180400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.000000</td>\n",
              "      <td>37.720000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3151.250000</td>\n",
              "      <td>648.250000</td>\n",
              "      <td>1721.000000</td>\n",
              "      <td>605.250000</td>\n",
              "      <td>4.767000</td>\n",
              "      <td>265000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>37937.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  17000.000000  17000.000000  ...   17000.000000        17000.000000\n",
              "mean    -119.562108     35.625225  ...       3.883578       207300.912353\n",
              "std        2.005166      2.137340  ...       1.908157       115983.764387\n",
              "min     -124.350000     32.540000  ...       0.499900        14999.000000\n",
              "25%     -121.790000     33.930000  ...       2.566375       119400.000000\n",
              "50%     -118.490000     34.250000  ...       3.544600       180400.000000\n",
              "75%     -118.000000     37.720000  ...       4.767000       265000.000000\n",
              "max     -114.310000     41.950000  ...      15.000100       500001.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "91GyClTHNJ_V",
        "colab": {}
      },
      "source": [
        "# X= california_housing_dataframe[\"total_rooms\", \"population\", \"total_bedrooms\", \"median_income\"].values\n",
        "X= california_housing_dataframe[['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']].values\n",
        "Y= california_housing_dataframe[\"median_house_value\"].values/ 10000.0\n",
        "\n",
        "# X= np.reshape(X, (-1, 1))\n",
        "Y= np.reshape(Y, (-1, 1))\n",
        "\n",
        "train_features , test_features ,train_labels, test_labels = train_test_split( X , Y , test_size=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ONt7e0lNp7h",
        "colab_type": "code",
        "outputId": "5da74984-aea7-41fa-b6e6-11d2f968025d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model= tf.keras.Sequential(){}\n",
        "model.add(tf.keras.layers.Dense(6, activation= 'relu'))\n",
        "model.add(tf.keras.layers.Dense(4, activation= 'relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation= 'relu'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-192-cec98f723b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \"\"\"\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1303\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDBgwxGXOezM",
        "colab_type": "code",
        "outputId": "42101d4a-fab7-4f5a-8354-d92eb798a44d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.compile(\n",
        "    optimizer= 'adam',\n",
        "    loss='mean_squared_error'\n",
        ")\n",
        "\n",
        "trained= model.fit(x= train_features, y= train_labels, epochs= 20, verbose= 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13600 samples\n",
            "Epoch 1/20\n",
            "13600/13600 [==============================] - 1s 95us/sample - loss: 9573.7766\n",
            "Epoch 2/20\n",
            "13600/13600 [==============================] - 1s 75us/sample - loss: 575.3915\n",
            "Epoch 3/20\n",
            "13600/13600 [==============================] - 1s 78us/sample - loss: 569.0013\n",
            "Epoch 4/20\n",
            "13600/13600 [==============================] - 1s 78us/sample - loss: 566.1147\n",
            "Epoch 5/20\n",
            "13600/13600 [==============================] - 1s 76us/sample - loss: 565.3134\n",
            "Epoch 6/20\n",
            "13600/13600 [==============================] - 1s 78us/sample - loss: 565.2376\n",
            "Epoch 7/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.2390\n",
            "Epoch 8/20\n",
            "13600/13600 [==============================] - 1s 80us/sample - loss: 565.2416\n",
            "Epoch 9/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.2633\n",
            "Epoch 10/20\n",
            "13600/13600 [==============================] - 1s 78us/sample - loss: 565.2340\n",
            "Epoch 11/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.2551\n",
            "Epoch 12/20\n",
            "13600/13600 [==============================] - 1s 78us/sample - loss: 565.2373\n",
            "Epoch 13/20\n",
            "13600/13600 [==============================] - 1s 76us/sample - loss: 565.3099\n",
            "Epoch 14/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.2784\n",
            "Epoch 15/20\n",
            "13600/13600 [==============================] - 1s 76us/sample - loss: 565.3660\n",
            "Epoch 16/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.3364\n",
            "Epoch 17/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.3434\n",
            "Epoch 18/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.3347\n",
            "Epoch 19/20\n",
            "13600/13600 [==============================] - 1s 79us/sample - loss: 565.3407\n",
            "Epoch 20/20\n",
            "13600/13600 [==============================] - 1s 77us/sample - loss: 565.3329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NGgKtqoPgoC",
        "colab_type": "code",
        "outputId": "8ac2654b-2290-4c3f-f738-526e71f072b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "evaluation= model.evaluate(x= test_features, y= test_labels, batch_size= 512, verbose= 1)\n",
        "print(evaluation)\n",
        "# for name, value in zip(model.metrics_names, evaluation):\n",
        "#   print(\"%s: %0.3f\" %(name, value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3400/3400 [==============================] - 0s 21us/sample - loss: 559.8810\n",
            "559.8810146197151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sQeV4tjGQyIx"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "This uses sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7091c582-d3b8-46c7-ab2a-861d858b75c4",
        "id": "yKH15ub0QyIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"Eager:\", \"true\" if tf.executing_eagerly else \"false\")\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.1.0-rc1\n",
            "Eager: true\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwEISuRQRDER",
        "colab_type": "code",
        "outputId": "78bf706b-ed64-4274-8e1f-4a5bab72cfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "reg= LinearRegression().fit(train_features, train_labels)\n",
        "\n",
        "output= reg.predict(test_features)\n",
        "\n",
        "accuracy_op = tf.metrics.MeanAbsoluteError() \n",
        "accuracy_op.update_state( test_labels , output )\n",
        "print( 'Mean Absolute Error = {}'.format( accuracy_op.result().numpy() ) )\n",
        "\n",
        "accuracy_op = tf.metrics.RootMeanSquaredError() \n",
        "accuracy_op.update_state( test_labels , output )\n",
        "print( 'Root Mean Square Error = {}'.format( accuracy_op.result().numpy() ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error = 5.515396595001221\n",
            "Root Mean Square Error = 7.550936222076416\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}